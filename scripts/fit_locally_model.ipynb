{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=https://obis.org/images/logo.png width=\"300\">   \n",
    "\n",
    "<div style=\"width: 100%; background-color: #0277d4; margin-top: 10px;\">&nbsp;</div>\n",
    "\n",
    "# Model the distribution of species _SPECIES_NAME_\n",
    "\n",
    "This notebook provides the code to run the model for _SPECIES_NAME_ (AphiaID APHIA_ID) using the method ALGO_NAME.\n",
    "\n",
    "Before starting you will need to:\n",
    "\n",
    "1. Download the full data for the species and put the downloaded (and unzipped) 'taxonid=APHIA_ID' folder to a folder called \"data\" in the working directory of this notebook.\n",
    "2. Install the requirements (see below)\n",
    "\n",
    "### Requirements\n",
    "\n",
    "You need to install some packages before being able to run this notebook. Run the next cell to install the necessary packages.\n",
    "\n",
    "### NOTES\n",
    "- this code does not cover ESMs (Ensemble of Small Models).\n",
    "- this code is a simplified version of our modelling framework. To understand the full range of decisions, see [this code](https://github.com/iobis/mpaeu_sdm/blob/main/codes/model_fit.R) and the [associated function](https://github.com/iobis/mpaeu_sdm/blob/main/functions/model_species.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(c(\"ragg\", \"ecospat\", \"terra\", \"jsonlite\", \"glue\", \"arrow\", \"cli\", \"fs\", \"ALGO_PACKAGE\"))\n",
    "devtools::install_github(\"iobis/mpaeu_msdm\")\n",
    "devtools::install_github(\"bio-oracle/biooracler\")\n",
    "devtools::install_github(\"sjevelazco/flexsdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(terra)\n",
    "library(obissdm)\n",
    "library(ALGO_PACKAGE)\n",
    "\n",
    "set.seed(2023)\n",
    "species_id <- APHIA_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the necessary packages installed, we need to download the environmental data. We will use the function `obissdm::get_env_data()` to download the data from Bio-ORACLE. We first load the log file to get the information of used layers and the habitat depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_log <- jsonlite::read_json(glue::glue(\"data/taxonid={species_id}/model=mpaeu/taxonid={species_id}_model=mpaeu_what=log.json\"))\n",
    "layer_names <- unlist(model_log$model_details$variables)\n",
    "print(layer_names)\n",
    "\n",
    "hab_depth <- model_log$hab_depth[[1]]\n",
    "print(hab_depth)\n",
    "\n",
    "sat_vars <- layer_names[grepl(\"_\", layer_names)]\n",
    "terrain_vars <- layer_names[!grepl(\"_\", layer_names)]\n",
    "\n",
    "sat_vars <- sat_vars[sat_vars != \"bathymetry_mean\"]\n",
    "terrain_vars <- c(terrain_vars, \"bathymetry_mean\")\n",
    "terrain_vars <- ifelse(terrain_vars == \"rugosity\", \"terrain_ruggedness_index\", terrain_vars)\n",
    "if (\"distcoast\" %in% terrain_vars || \"wavefetch\" %in% terrain_vars) {\n",
    "    aws_layers <- terrain_vars[terrain_vars %in% c(\"distcoast\", \"wavefetch\")]\n",
    "    terrain_vars <- terrain_vars[!terrain_vars %in% c(\"distcoast\", \"wavefetch\")]\n",
    "} else {\n",
    "    aws_layers <- NULL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# List datasets to download ----\n",
    "datasets <- c(\n",
    "  \"thetao_baseline_2000_2019_depthsurf\",\n",
    "  \"so_baseline_2000_2019_depthsurf\",\n",
    "  \"PAR_mean_baseline_2000_2020_depthsurf\",\n",
    "  \"phyc_baseline_2000_2020_depthsurf\",\n",
    "  \"ph_baseline_2000_2018_depthsurf\",\n",
    "  \"sws_baseline_2000_2019_depthsurf\",\n",
    "  \"siconc_baseline_2000_2020_depthsurf\",\n",
    "  \"o2_baseline_2000_2018_depthsurf\",\n",
    "  \"KDPAR_mean_baseline_2000_2020_depthsurf\",\n",
    "  \"no3_baseline_2000_2018_depthsurf\",\n",
    "  \"chl_baseline_2000_2018_depthsurf\",\n",
    "  \"tas_baseline_2000_2020_depthsurf\",\n",
    "  \"si_baseline_2000_2018_depthsurf\",\n",
    "  \"mlotst_baseline_2000_2019_depthsurf\"\n",
    ")\n",
    "\n",
    "datasets <- datasets[grepl(paste0(gsub(\"_.*\", \"\", sat_vars), collapse = \"|\"),\n",
    " datasets, ignore.case = T)]\n",
    "\n",
    "datasets <- gsub(\"depthsurf\", hab_depth, datasets)\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### Change here if you want to download just a subset of the scenarios\n",
    "# List scenarios to download ----\n",
    "future_scenarios <- c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp460\", \"ssp585\")\n",
    "\n",
    "### Change here if you want to download for a different time period\n",
    "# Define time steps ----\n",
    "time_steps <- list(\n",
    "  current = c(\"2000-01-01T00:00:00Z\", \"2010-01-01T00:00:00Z\"), #2000-2010/2010-2020\n",
    "  dec50 = c(\"2030-01-01\", \"2040-01-01\"), #2030-2040/2040-2050\n",
    "  dec100 = c(\"2080-01-01\", \"2090-01-01\") #2080-2090/2090-2100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "for (i in seq_along(sat_vars)) {\n",
    "    variable <- gsub(\"_.*\", \"\", sat_vars[i])\n",
    "    variant <- gsub(\".*._\", \"\", sat_vars[i])\n",
    "    sel_dataset <- datasets[grepl(variable, datasets)]\n",
    "    get_env_data(datasets = sel_dataset, future_scenarios = future_scenarios,\n",
    "             time_steps = time_steps, variables = variant,\n",
    "             average_time = T)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Now the terrain variables\n",
    "if (length(terrain_vars) > 0) {\n",
    "    get_env_data(terrain_vars = terrain_vars)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# And then layers not available on Bio-ORACLE\n",
    "if (!is.null(aws_layers)) {\n",
    "    if (\"distcoast\" %in% aws_layers) {\n",
    "        download.file(\"https://mpaeu-dist.s3.amazonaws.com/source/data/env/terrain/distcoast.tif\",\n",
    "        destfile = \"data/env/terrain/distcoast.tif\", method = \"wget\")\n",
    "    }\n",
    "    if (\"wavefetch\" %in% aws_layers) {\n",
    "        download.file(\"https://mpaeu-dist.s3.amazonaws.com/source/data/env/terrain/wavefetch.tif\",\n",
    "        destfile = \"data/env/terrain/wavefetch.tif\", method = \"wget\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few checks that should be done with the environmental layers before proceeding. Also, note that if any download failed you just need to run again the cell - it will not download again what was already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "if (any(grepl(\"chl\", sat_vars)) && hab_depth != \"depthsurf\") {\n",
    "    # For Chlorophyll-a we remove the depthmean and depthmax, as for the future is\n",
    "    # not available\n",
    "    to_remove <- list.files(\"data/env/current\", full.names = T)\n",
    "    to_remove <- to_remove[grepl(\"chl\", to_remove)]\n",
    "    to_remove <- to_remove[grepl(\"depthmean|depthmax\", to_remove)]\n",
    "    fs::file_delete(to_remove)\n",
    "}\n",
    "\n",
    "if (any(grepl(\"kd\", sat_vars))) {\n",
    "    # Rename KDPAR for kd\n",
    "    to_rename <- list.files(\"data/env\", recursive = T, full.names = T)\n",
    "    to_rename <- to_rename[grepl(\"kdpar\", to_rename)]\n",
    "    new_names <- gsub(\"kdpar\", \"kd\", to_rename)\n",
    "    file.rename(to_rename, new_names)\n",
    "}\n",
    "\n",
    "if (any(grepl(\"terrain_ruggedness_index\", terrain_vars))) {\n",
    "    # Rename terrain_ruggedness\n",
    "    to_rename <- list.files(\"data/env/terrain/\", recursive = T, full.names = T)\n",
    "    to_rename <- to_rename[grepl(\"rugg\", to_rename)]\n",
    "    to_rename <- to_rename[!grepl(\"aux\", to_rename)]\n",
    "    new_names <- gsub(\"terrain_ruggedness_index\", \"rugosity\", to_rename)\n",
    "    edit_r <- terra::rast(to_rename)\n",
    "    names(edit_r) <- \"rugosity\"\n",
    "    terra::writeRaster(edit_r, new_names, overwrite = T)\n",
    "    fs::file_delete(to_rename)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all data on the folder, we can start the modelling. First, we load and prepare the environmental data according to the project settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Select environmental layers\n",
    "env_files <- c(\n",
    "    list.files(\"data/env/current\", full.names = T),\n",
    "    list.files(\"data/env/terrain\", full.names = T)\n",
    ")\n",
    "env_files <- env_files[grepl(\n",
    "    paste0(gsub(\"_\", paste0(\"_baseline_\", hab_depth, \"_\"), layer_names), collapse = \"|\"), env_files)]\n",
    "env_files <- env_files[!grepl(\".json\", env_files)]\n",
    "print(env_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load masks\n",
    "masks <- rast(glue::glue(\"data/taxonid={species_id}/model=mpaeu/predictions/taxonid={species_id}_model=mpaeu_mask_cog.tif\"))\n",
    "NAflag(masks) <- 0\n",
    "masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load environmental layer and apply the mask\n",
    "env <- rast(env_files)\n",
    "env <- terra::mask(env, masks$fit_region)\n",
    "print(env)\n",
    "plot(env[[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we prepare the data object for the SDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "quad_n <- model_log$model_details$background_size[[1]]\n",
    "fit_pts <- arrow::read_parquet(glue::glue(\"data/taxonid={species_id}/model=mpaeu/taxonid={species_id}_model=mpaeu_what=fitocc.parquet\"))\n",
    "species_name <- model_log$scientificName[[1]]\n",
    "\n",
    "sp_data <- mp_prepare_data(\n",
    "    training = fit_pts,\n",
    "    eval_data = NULL,\n",
    "    species_id = species_name,\n",
    "    env_layers = env,\n",
    "    quad_number = quad_n,\n",
    "    verbose = TRUE\n",
    ")\n",
    "\n",
    "block_grid <- get_block_grid(sp_data, env,\n",
    "    sel_vars = names(env),\n",
    "    verbose = TRUE\n",
    ")\n",
    "\n",
    "sp_data <- mp_prepare_blocks(sp_data,\n",
    "    method = \"manual\",\n",
    "    block_types = \"spatial_grid\",\n",
    "    n_iterate = 300,\n",
    "    retry_if_zero = TRUE,\n",
    "    manual_shp = block_grid,\n",
    "    verbose = TRUE\n",
    ")\n",
    "\n",
    "if (any(table(sp_data$training$presence, sp_data$blocks$folds[[\"spatial_grid\"]])[2, ] == 0)) {\n",
    "    stop(\"Blocks with less than 1 point. Failed.\")\n",
    "}\n",
    "\n",
    "sp_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start the modelling. We need to prepare the settings for the model tunning. Here is your opportunity to modify the settings that we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_options <- sdm_options(\"ALGO_NAME\")\n",
    "used_options <- model_log$algorithms_parameters$ALGO_NAME\n",
    "for (i in 1:length(used_options)) {\n",
    "    if (names(used_options)[i] %in% names(model_options)) {\n",
    "        model_options[[names(used_options)[i]]] <- unlist(used_options[i], recursive = T, use.names = F)\n",
    "    }\n",
    "}\n",
    "model_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model_fit <- sdm_fit(sp_data, sdm_method = \"ALGO_NAME\", options = model_options)\n",
    "model_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model fitted, we can predict to the current and future scenarios. Note that this will take some time! You can speed things up by reducing the number of scenarios/decades (see comment below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pred_model <- function(model, pred_out, species, outacro) {\n",
    "    model_name <- model$name\n",
    "    cli::cli_alert_info(\"Predicting model {id} - {model_name}\")\n",
    "\n",
    "    if (!dir.exists(pred_out)) fs::dir_create(pred_out)\n",
    "\n",
    "    outmess <- file.path(pred_out, paste0(\"taxonid=\", species, \"_model=\", outacro, \"_what=mess.tif\"))\n",
    "    outshape <- file.path(pred_out, paste0(\"taxonid=\", species, \"_model=\", outacro, \"_what=shape.tif\"))\n",
    "\n",
    "    scenarios <- data.frame(\n",
    "        scenario = c(\"current\", rep(c(\"ssp126\", \"ssp245\", \"ssp370\", \"ssp460\", \"ssp585\"),\n",
    "            each = 2\n",
    "        )),\n",
    "        year = c(NA, rep(c(\"dec50\", \"dec100\"), 5))\n",
    "    )\n",
    "\n",
    "    # If you want to reduce the number of scenarios you simply edit the above lines\n",
    "    # as is done below:\n",
    "    scenarios <- data.frame(scenario = c(\"current\", \"ssp126\"), year = c(NA,\"dec50\"))\n",
    "    #scenarios <- data.frame(scenario = c(\"current\"), year = c(NA))\n",
    "\n",
    "    for (k in 1:nrow(scenarios)) {\n",
    "        if (is.na(scenarios$year[k])) {\n",
    "            period <- NULL\n",
    "        } else {\n",
    "            period <- scenarios$year[k]\n",
    "        }\n",
    "\n",
    "        cli::cli_alert_info(\"Predicting scenario {k} of {nrow(scenarios)}.\")\n",
    "        outpred <- file.path(pred_out, paste0(\n",
    "            \"taxonid=\", species, \"_model=\", outacro,\n",
    "            \"_method=\", model_name, \"_scen=\", scenarios$scenario[k],\n",
    "            ifelse(is.null(period), \"\", paste0(\"_\", period)), \".tif\"\n",
    "        ))\n",
    "\n",
    "        if (scenarios$scenario[k] != \"current\") {\n",
    "            env_files_ed <- gsub(\"current/\", paste0(\"future/\", scenarios$scenario[k], \"/\"), env_files)\n",
    "            env_files_ed <- gsub(\"baseline\", scenarios$scenario[k], env_files_ed)\n",
    "            env_files_ed <- gsub(hab_depth, paste0(hab_depth, \"_\", period), env_files_ed)\n",
    "        } else {\n",
    "            env_files_ed <- env_files\n",
    "        }\n",
    "        env_to_pred <- terra::rast(env_files_ed)\n",
    "\n",
    "        pred <- predict(model, env_to_pred)\n",
    "\n",
    "        names(pred) <- paste0(scenarios$scenario[k], ifelse(is.null(period), \"\", paste0(\"_\", period)))\n",
    "\n",
    "        pred <- pred * 100\n",
    "        pred <- as.int(pred)\n",
    "        writeRaster(pred, outpred, overwrite = T, datatype = \"INT1U\")\n",
    "\n",
    "        if (k == 1) {\n",
    "            pred_f <- pred\n",
    "        }\n",
    "\n",
    "        # Save MESS\n",
    "        cli::cli_alert_info(\"Generating MESS map.\")\n",
    "        to_mess <- terra::aggregate(env_to_pred, 12)\n",
    "        mess_map <- ecospat::ecospat.mess(\n",
    "            na.omit(as.data.frame(to_mess, xy = T)),\n",
    "            cbind(sp_data$coord_training, sp_data$training[, 2:ncol(sp_data$training)])\n",
    "        )\n",
    "        mess_map_t <- to_mess[[1]]\n",
    "        mess_map_t[] <- NA\n",
    "        mess_map_t[cellFromXY(mess_map_t, mess_map[, 1:2])] <- mess_map[, 5]\n",
    "        mess_map <- mess_map_t\n",
    "\n",
    "        names(mess_map) <- names(pred) <- paste0(scenarios$scenario[k], ifelse(is.null(period), \"\", paste0(\"_\", period)))\n",
    "\n",
    "        if (k == 1) {\n",
    "            pred_mess <- mess_map\n",
    "        } else {\n",
    "            pred_mess <- c(pred_mess, mess_map)\n",
    "        }\n",
    "\n",
    "        cli::cli_alert_info(\"Generating SHAPE map.\")\n",
    "        # Reduce dataset for faster implementing\n",
    "        shape_data <- sp_data$training\n",
    "        which_p <- which(shape_data$presence == 1)\n",
    "        if (sum(shape_data$presence) > 1000) {\n",
    "            which_p <- sample(which_p, 1000)\n",
    "        }\n",
    "        which_a <- sample(which(shape_data$presence == 0), 1000)\n",
    "        shape_data <- shape_data[c(which_p, which_a), ]\n",
    "        shape_data_coords <- sp_data$coord_training[c(which_p, which_a), ]\n",
    "        names(shape_data_coords) <- c(\"x\", \"y\")\n",
    "\n",
    "        shape_res <- try(flexsdm::extra_eval(\n",
    "            shape_data,\n",
    "            \"presence\",\n",
    "            projection_data = env_to_pred,\n",
    "            aggreg_factor = 12 # For faster implementing\n",
    "        ), silent = T)\n",
    "\n",
    "        if (!inherits(shape_res, \"try-error\")) {\n",
    "            if (k == 1) {\n",
    "                outpath_fig <- paste0(pred_out, \"/figures/\")\n",
    "                if (!dir.exists(outpath_fig)) fs::dir_create(outpath_fig)\n",
    "                outfile_fig <- paste0(\n",
    "                    outpath_fig,\n",
    "                    \"taxonid=\", species, \"_model=\", outacro, \"_method=\", model_name,\n",
    "                    \"_what=shape.png\"\n",
    "                )\n",
    "                shape_plot <- suppressMessages(\n",
    "                    try(flexsdm::p_extra(\n",
    "                        training_data = cbind(shape_data_coords, shape_data),\n",
    "                        pr_ab = \"presence\",\n",
    "                        extra_suit_data = terra::aggregate(shape_res, 12),\n",
    "                        projection_data = terra::aggregate(env_to_pred, 12),\n",
    "                        geo_space = TRUE,\n",
    "                        prop_points = 0.05,\n",
    "                        alpha_p = 0.2\n",
    "                    ), silent = T)\n",
    "                )\n",
    "\n",
    "                ragg::agg_png(outfile_fig, width = 6, height = 2.5, units = \"in\", res = 300, scaling = 0.4)\n",
    "                print(shape_plot)\n",
    "                dof <- dev.off()\n",
    "                rm(dof, shape_plot)\n",
    "            }\n",
    "\n",
    "            shape_res <- aggregate(shape_res, fact = 12)\n",
    "            shape_res <- as.int(shape_res)\n",
    "            names(shape_res) <- paste0(scenarios$scenario[k], ifelse(is.null(period), \"\", paste0(\"_\", period)))\n",
    "\n",
    "            if (k == 1) {\n",
    "                pred_shape <- shape_res\n",
    "            } else {\n",
    "                pred_shape <- c(pred_shape, shape_res)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pred_mess <- as.int(pred_mess)\n",
    "    writeRaster(pred_mess, outmess, overwrite = T, datatype = \"INT1U\")\n",
    "    writeRaster(pred_shape, outshape, overwrite = T, datatype = \"INT2U\")\n",
    "\n",
    "    cat(\"Predictions concluded\")\n",
    "    return(invisible(NULL))\n",
    "}\n",
    "\n",
    "pred_model(model_fit, \"results\", species = species_id, outacro = \"myrun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that our modelling and prediction is concluded. You may want to experiment creating [other masks](https://github.com/iobis/mpaeu_sdm/blob/main/functions/model_species.R#L874) or trying other [thresholds](https://github.com/iobis/mpaeu_sdm/blob/main/functions/model_species.R#L835)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
